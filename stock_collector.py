import os
import asyncio
import yfinance as yf
import pandas as pd
import talib
from supabase import create_client, Client
import requests 
from datetime import datetime, timedelta


# --- Configuration ---
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
TWELVE_DATA_KEY = os.getenv("TWELVE_DATA_KEY")
FINNHUB_KEY = os.getenv("FINNHUB_KEY") 

if not SUPABASE_URL or not SUPABASE_KEY:
    raise ValueError("‚ùå Missing SUPABASE_URL or SUPABASE_KEY")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)


def calculate_overall_score(symbol, tech_data, fundamental_data, news_sentiment):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Overall Score ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ AI API
    Score: 0-100 (integer)
    """
    
    score = 50  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà 50 (‡∏Å‡∏•‡∏≤‡∏á‡πÜ)
    
    # === 1. Technical Score (40 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô) ===
    technical_score = 0
    
    # RSI (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
    rsi = tech_data.get('rsi')
    if rsi:
        if 30 <= rsi <= 70:
            technical_score += 10
        elif 20 <= rsi < 30 or 70 < rsi <= 80:
            technical_score += 5
    
    # MACD (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
    macd = tech_data.get('macd')
    macd_signal = tech_data.get('macd_signal')
    if macd and macd_signal:
        if macd > macd_signal:
            technical_score += 10
        elif macd > macd_signal * 0.9:
            technical_score += 5
    
    # EMA Trend (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
    price = tech_data.get('price')
    ema_20 = tech_data.get('ema_20')
    ema_50 = tech_data.get('ema_50')
    ema_200 = tech_data.get('ema_200')
    
    if price and ema_20 and ema_50:
        if price > ema_20 > ema_50:
            technical_score += 10
        elif price > ema_20:
            technical_score += 5
    
    # Upside Potential (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
    upside_pct = tech_data.get('upside_pct')
    if upside_pct:
        if upside_pct > 20:
            technical_score += 10
        elif upside_pct > 10:
            technical_score += 7
        elif upside_pct > 5:
            technical_score += 4
    
    score += (technical_score / 40) * 40
    
    
    # === 2. Fundamental Score (30 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô) ===
    fundamental_score = 0
    
    if fundamental_data:
        pe_ratio = fundamental_data.get('pe_ratio')
        if pe_ratio:
            if 10 <= pe_ratio <= 25:
                fundamental_score += 10
            elif 5 <= pe_ratio < 10 or 25 < pe_ratio <= 35:
                fundamental_score += 5
        
        peg_ratio = fundamental_data.get('peg_ratio')
        if peg_ratio:
            if peg_ratio < 1:
                fundamental_score += 10
            elif 1 <= peg_ratio <= 1.5:
                fundamental_score += 7
            elif 1.5 < peg_ratio <= 2:
                fundamental_score += 4
        
        eps_growth = fundamental_data.get('eps_growth_pct')
        if eps_growth:
            if eps_growth > 20:
                fundamental_score += 10
            elif eps_growth > 10:
                fundamental_score += 7
            elif eps_growth > 5:
                fundamental_score += 4
    
    score += (fundamental_score / 30) * 30
    
    
    # === 3. Sentiment Score (30 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô) ===
    sentiment_score = 0
    
    if news_sentiment:
        if news_sentiment > 0.5:
            sentiment_score += 15
        elif news_sentiment > 0.2:
            sentiment_score += 10
        elif news_sentiment >= -0.2:
            sentiment_score += 5
    
    analyst_buy_pct = tech_data.get('analyst_buy_pct')
    if analyst_buy_pct:
        if analyst_buy_pct >= 70:
            sentiment_score += 15
        elif analyst_buy_pct >= 50:
            sentiment_score += 10
        elif analyst_buy_pct >= 30:
            sentiment_score += 5
    
    score += (sentiment_score / 30) * 30
    
    # ‚¨áÔ∏è ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô int
    return int(min(100, max(0, round(score))))  # ‚úÖ ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô integer


def generate_recommendation(overall_score, price, upside_pct):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å Score"""
    
    if overall_score >= 75:
        recommendation = "Strong Buy"
        reason = "Excellent technical and fundamental indicators"
    elif overall_score >= 60:
        recommendation = "Buy"
        reason = "Good growth potential with positive momentum"
    elif overall_score >= 45:
        recommendation = "Hold"
        reason = "Wait for better entry point or confirmation"
    elif overall_score >= 30:
        recommendation = "Sell"
        reason = "Weak signals, consider taking profits"
    else:
        recommendation = "Strong Sell"
        reason = "Poor performance across all metrics"
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° price target
    if upside_pct and upside_pct > 0:
        price_target = round(price * (1 + upside_pct / 100), 2)
    else:
        price_target = None
    
    return recommendation, reason, price_target


def calculate_actual_outcome(symbol, prediction_date):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å 30 ‡∏ß‡∏±‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï)
    """
    try:
        # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        current_snapshot = supabase.table("stock_snapshots")\
            .select("price")\
            .eq("symbol", symbol)\
            .order("recorded_at", desc=True)\
            .limit(1)\
            .execute()
        
        if not current_snapshot.data:
            return None
        
        current_price = current_snapshot.data[0]['price']
        
        # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡∏≠‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        prediction_snapshot = supabase.table("stock_snapshots")\
            .select("price")\
            .eq("symbol", symbol)\
            .lte("recorded_at", prediction_date)\
            .order("recorded_at", desc=True)\
            .limit(1)\
            .execute()
        
        if not prediction_snapshot.data:
            return None
        
        prediction_price = prediction_snapshot.data[0]['price']
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì % ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
        return round(((current_price - prediction_price) / prediction_price) * 100, 2)
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error calculating actual outcome: {e}")
        return None


def fetch_news_data(symbol):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Finnhub API ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì sentiment + ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
    try:
        if not FINNHUB_KEY or FINNHUB_KEY == "":
            print(f"‚ö†Ô∏è FINNHUB_KEY not configured, skipping news for {symbol}")
            return []
        
        # 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤: 7 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        to_date = datetime.now()
        from_date = to_date - timedelta(days=7)
        
        # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° URL ‡πÅ‡∏•‡∏∞ Parameters
        url = "https://finnhub.io/api/v1/company-news"
        params = {
            "symbol": symbol,
            "from": from_date.strftime('%Y-%m-%d'),
            "to": to_date.strftime('%Y-%m-%d'),
            "token": FINNHUB_KEY
        }
        
        # 3. ‡∏¢‡∏¥‡∏á Request ‡πÑ‡∏õ‡∏ó‡∏µ‡πà API
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        # 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if not data or not isinstance(data, list):
            print(f"üì≠ No news available for {symbol}")
            return []
        
        print(f"üì∞ Found {len(data)} news articles for {symbol}")
        
        # 5. ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 10 ‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        news_list = data[:10]
        
        # 6. ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        try:
            translator = GoogleTranslator(source='en', target='th')
            for news in news_list:
                headline = news.get('headline', '')
                summary = news.get('summary', '')
                
                if headline:
                    news['headline_th'] = translator.translate(headline)
                
                if summary:
                    news['summary_th'] = translator.translate(summary[:4500])
        except Exception as trans_error:
            print(f"‚ö†Ô∏è Translation failed for {symbol}: {trans_error}")
            # ‡∏ñ‡πâ‡∏≤‡πÅ‡∏õ‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏î‡∏¥‡∏°
 
 

        positive_keywords = [
            # Price Movement (‡∏Ç‡∏∂‡πâ‡∏ô/‡∏î‡∏µ)
            'surge', 'soar', 'jump', 'gain', 'rise', 'rally', 'climb', 'spike', 
            'advance', 'boost', 'pop', 'breakout', 'breakthrough', 'skyrocket',
            
            # Trend & Market (‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏î‡∏µ)
            'bull', 'bullish', 'uptrend', 'momentum', 'strength', 'resilient',
            
            # Performance (‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏î‡∏µ)
            'beat', 'exceed', 'outperform', 'top', 'best', 'leading', 'dominance',
            'strong', 'robust', 'solid', 'impressive', 'stellar', 'outstanding',
            
            # Growth & Expansion (‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï)
            'growth', 'expand', 'expansion', 'increase', 'accelerate', 'boom',
            'thriving', 'flourish', 'prosper',
            
            # Records & Achievements (‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)
            'record', 'high', 'peak', 'all-time', 'milestone', 'historic',
            'breakthrough', 'achievement',
            
            # Upgrades & Ratings (‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î)
            'upgrade', 'upgraded', 'raised', 'lift', 'improve', 'improved',
            'positive', 'optimistic', 'confidence', 'bullish',
            
            # Profits & Revenue (‡∏Å‡∏≥‡πÑ‡∏£)
            'profit', 'profitable', 'revenue', 'earnings', 'income', 'dividend',
            
            # Success & Winners (‡∏ä‡∏ô‡∏∞/‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)
            'win', 'winner', 'winning', 'success', 'successful', 'triumph',
            
            # Sentiment (‡∏ö‡∏ß‡∏Å)
            'optimism', 'hope', 'excited', 'enthusiasm', 'promising', 'favorable',
            'opportunity', 'potential', 'bright', 'positive',
            
            # Guidance & Outlook (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏∏‡πâ‡∏ô Growth)
            'raise guidance', 'raised outlook', 'upward revision', 'beat-and-raise', 'favorable outlook',
            
            # Tech & AI Specific (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NVDA / Tech)
            'ai demand', 'gpu demand', 'data center growth', 'next-gen', 'backlog', 'production ramp',
            'market share gain', 'technological lead', 'innovation',
            
            # Subscription & User Base (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NFLX)
            'subscriber growth', 'low churn', 'content hit', 'ad-tier success', 'average revenue per user',
            
            # Options & Technical Signals
            'short squeeze', 'gamma squeeze', 'consolidation breakout', 'accumulation', 'high volume rally',
            
            # Valuation & GARP
            'undervalued', 'attractive valuation', 'reasonable price', 'strong cash flow', 'buyback', 'share repurchase'
        ]
        
        negative_keywords = [
            # Price Movement (‡∏•‡∏á/‡πÅ‡∏¢‡πà)
            'fall', 'drop', 'plunge', 'crash', 'tumble', 'sink', 'slide', 'slump',
            'decline', 'decrease', 'dive', 'plummet', 'collapse', 'tank', 'nosedive',
            
            # Trend & Market (‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡πÅ‡∏¢‡πà)
            'bear', 'bearish', 'downtrend', 'downturn', 'recession', 'correction',
            
            # Performance (‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡πÅ‡∏¢‡πà)
            'miss', 'missed', 'underperform', 'disappoint', 'disappointing',
            'weak', 'weaken', 'poor', 'worst', 'struggle', 'struggling',
            'fail', 'failure', 'failed', 'underwhelm',
            
            # Loss & Damage (‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô/‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢)
            'loss', 'losses', 'losing', 'deficit', 'debt', 'bankrupt', 'bankruptcy',
            'insolvent', 'write-down', 'impairment',
            
            # Risk & Concern (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á/‡∏Å‡∏±‡∏á‡∏ß‡∏•)
            'concern', 'concerned', 'worry', 'worried', 'fear', 'fearful', 'anxiety',
            'risk', 'risky', 'danger', 'threat', 'threaten', 'warning', 'alert',
            'uncertain', 'uncertainty', 'doubt', 'skeptical', 'cautious',
            
            # Downgrades & Negative Ratings (‡∏•‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö)
            'downgrade', 'downgraded', 'cut', 'lower', 'lowered', 'reduce', 'reduced',
            'negative', 'pessimistic',
            
            # Crisis & Problems (‡∏ß‡∏¥‡∏Å‡∏§‡∏ï/‡∏õ‡∏±‡∏ç‡∏´‡∏≤)
            'crisis', 'problem', 'issue', 'trouble', 'challenge', 'difficulty',
            'setback', 'hurdle', 'obstacle',
            
            # Records & Extremes (‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏¢‡πà)
            'low', 'bottom', 'trough', 'lowest', 'worst', 'record-low',
            
            # Legal & Regulatory (‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢/‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°)
            'lawsuit', 'sue', 'sued', 'investigation', 'probe', 'fine', 'penalty',
            'violation', 'fraud', 'scandal',
            
            # Layoffs & Cuts (‡∏•‡∏î‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô/‡∏ï‡∏±‡∏î)
            'layoff', 'layoffs', 'fire', 'fired', 'cut', 'cuts', 'cutting',
            'eliminate', 'restructure', 'downsize',
            
            # Sentiment (‡∏•‡∏ö)
            'pessimism', 'gloomy', 'bleak', 'dire', 'dismal', 'disappointing',

            # Guidance & Outlook (‡∏ï‡∏±‡∏ß‡∏ó‡∏≥‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô Tech)
            'lowered guidance', 'guidance cut', 'weak outlook', 'downward revision', 'cautious guidance',
            'shortfall', 'missed estimates',
            
            # Tech & AI Specific
            'supply constraints', 'chip ban', 'export restriction', 'inventory glut', 'component shortage',
            'obsolescence', 'stiff competition',
            
            # Subscription & User Base (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NFLX)
            'subscriber loss', 'high churn', 'content fatigue', 'account sharing crackdown impact',
            
            # Macro & Regulatory (‡∏Å‡∏•‡∏∏‡πà‡∏° Tech ‡πÇ‡∏î‡∏ô‡∏ö‡πà‡∏≠‡∏¢)
            'antitrust', 'regulation', 'investigation', 'probe', 'monopoly concerns', 'interest rate hike',
            
            # Options & Technical Signals
            'overbought', 'valuation bubble', 'profit taking', 'distribution', 'dead cat bounce',
            
            # Valuation & Financials
            'overvalued', 'expensive', 'stretched valuation', 'cash burn', 'margin compression'
        ]
 
        # 8. ‡∏™‡∏£‡πâ‡∏≤‡∏á news_records ‡∏û‡∏£‡πâ‡∏≠‡∏° sentiment
        news_records = []
        
        for idx, news in enumerate(news_list, 1):
            headline = news.get('headline', '')
            
            if not headline:
                print(f"‚ö†Ô∏è News #{idx}: No headline found, skipping...")
                continue
            
            headline_lower = headline.lower()
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì sentiment
            pos_count = sum(1 for word in positive_keywords if word in headline_lower)
            neg_count = sum(1 for word in negative_keywords if word in headline_lower)
            
            if pos_count > 0 or neg_count > 0:
                sentiment = round((pos_count - neg_count) / max(pos_count + neg_count, 1), 2)
            else:
                sentiment = 0.0
            
            # ‡πÅ‡∏õ‡∏•‡∏á timestamp (Finnhub ‡πÉ‡∏ä‡πâ Unix timestamp)
            pub_timestamp = news.get('datetime')
            if pub_timestamp:
                published_at = datetime.fromtimestamp(pub_timestamp).isoformat()
            else:
                published_at = datetime.now().isoformat()
            
            news_record = {
                "symbol": symbol,
                "title": headline[:500],
                "title_th": news.get('headline_th', '')[:500] if news.get('headline_th') else None,
                "summary": news.get('summary', '')[:500] if news.get('summary') else None,
                "summary_th": news.get('summary_th', '')[:500] if news.get('summary_th') else None,
                "url": news.get('url', ''),
                "published_at": published_at,
                "source": news.get('source', 'Unknown'),
                "sentiment_score": sentiment
            }
            
            news_records.append(news_record)
            
            # Debug: ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡πÅ‡∏£‡∏Å
            if idx == 1:
                print(f"   Sample: {headline[:50]}...")
                print(f"   Thai: {news.get('headline_th', '')[:50]}...")
                print(f"   Sentiment: {sentiment} | Source: {news.get('source')}")
        
        return news_records
        
    except Exception as e:
        print(f"‚ö†Ô∏è Cannot fetch news for {symbol}: {e}")
        import traceback
        traceback.print_exc()
        return []
         
    
def fetch_fundamental_data(symbol):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Fundamental ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå GARP"""
    try:
        stock = yf.Ticker(symbol)
        info = stock.info
        
        return {
            "pe_ratio": info.get('forwardPE') or info.get('trailingPE'),
            "peg_ratio": info.get('pegRatio'),
            "eps_growth_pct": info.get('earningsGrowth', 0) * 100 if info.get('earningsGrowth') else None,
            "market_cap": info.get('marketCap')
        }
    except Exception as e:
        print(f"‚ö†Ô∏è Cannot fetch fundamental data for {symbol}: {e}")
        return {}

 
def calculate_technical_indicators(df):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏î‡πâ‡∏ß‡∏¢ TA-Lib"""
    try:
        if len(df) < 200:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 200 ‡πÅ‡∏ó‡πà‡∏á
            return None
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy arrays
        close = df['Close'].values
        high = df['High'].values
        low = df['Low'].values
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏î‡πâ‡∏ß‡∏¢ talib
        rsi = talib.RSI(close, timeperiod=14)
        macd, macd_signal, macd_hist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)
        ema_20 = talib.EMA(close, timeperiod=20)
        ema_50 = talib.EMA(close, timeperiod=50)
        ema_200 = talib.EMA(close, timeperiod=200)
        bb_upper, bb_middle, bb_lower = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2)
        
        # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        return {
            "price": float(close[-1]),
            "rsi": float(rsi[-1]) if not pd.isna(rsi[-1]) else None,
            "macd": float(macd[-1]) if not pd.isna(macd[-1]) else None,
            "macd_signal": float(macd_signal[-1]) if not pd.isna(macd_signal[-1]) else None,
            "ema_20": float(ema_20[-1]) if not pd.isna(ema_20[-1]) else None,
            "ema_50": float(ema_50[-1]) if not pd.isna(ema_50[-1]) else None,
            "ema_200": float(ema_200[-1]) if not pd.isna(ema_200[-1]) else None,
            "bb_upper": float(bb_upper[-1]) if not pd.isna(bb_upper[-1]) else None,
            "bb_lower": float(bb_lower[-1]) if not pd.isna(bb_lower[-1]) else None
        }
    except Exception as e:
        print(f"‚ùå Error calculating indicators: {e}")
        return None


def calculate_upside_pct(current_price, ema_200, ema_50=None):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì upside potential - ‡πÉ‡∏ä‡πâ EMA 200 ‡∏´‡∏£‡∏∑‡∏≠ EMA 50 ‡πÅ‡∏ó‡∏ô‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ"""
    if not current_price:
        return None
    
    # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ EMA 200 ‡∏Å‡πà‡∏≠‡∏ô
    if ema_200 and ema_200 > 0:
        return round(((ema_200 - current_price) / current_price) * 100, 2)
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ EMA 200 ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ EMA 50 ‡πÅ‡∏ó‡∏ô
    if ema_50 and ema_50 > 0:
        return round(((ema_50 - current_price) / current_price) * 100, 2)
    
    return None


def fetch_analyst_data(symbol):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Analyst Recommendations ‡∏à‡∏≤‡∏Å yfinance"""
    try:
        stock = yf.Ticker(symbol)
        recommendations = stock.recommendations
        
        if recommendations is not None and not recommendations.empty:
            recent = recommendations.tail(10)
            buy_grades = ['buy', 'strong buy', 'outperform', 'overweight']
            buy_count = 0
            
            for _, row in recent.iterrows():
                grade = str(row.get('To Grade', '')).lower()
                if any(buy_word in grade for buy_word in buy_grades):
                    buy_count += 1
            
            total = len(recent)
            return round((buy_count / total) * 100, 2) if total > 0 else None
            
    except Exception as e:
        print(f"‚ö†Ô∏è Cannot fetch analyst data for {symbol}: {e}")
    
    return None


def fetch_sentiment_score(symbol):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Sentiment Score ‡∏à‡∏≤‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á yfinance"""
    try:
        stock = yf.Ticker(symbol)
        news = stock.news
        
        if not news or len(news) == 0:
            return None
        
        positive_keywords = [
            'surge', 'soar', 'jump', 'gain', 'rise', 'rally', 'bull', 
            'upgrade', 'beat', 'strong', 'growth', 'record', 'high'
        ]
        negative_keywords = [
            'fall', 'drop', 'plunge', 'crash', 'bear', 'downgrade', 
            'miss', 'weak', 'loss', 'decline', 'low', 'concern'
        ]
        
        score = 0
        analyzed_count = 0
        
        for article in news[:20]:
            title = article.get('title', '').lower()
            pos_count = sum(1 for word in positive_keywords if word in title)
            neg_count = sum(1 for word in negative_keywords if word in title)
            
            if pos_count > 0 or neg_count > 0:
                score += pos_count - neg_count
                analyzed_count += 1
        
        if analyzed_count == 0:
            return None
        
        normalized_score = score / analyzed_count
        return round(max(-1, min(1, normalized_score)), 2)
        
    except Exception as e:
        print(f"‚ö†Ô∏è Cannot fetch sentiment for {symbol}: {e}")
    
    return None


async def fetch_data_waterfall(symbol):
    """‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏ô‡πâ‡∏≥‡∏ï‡∏Å: yfinance -> Twelve Data"""
    print(f"üîç Fetching data for {symbol}...")
    
    # --- Source 1: yfinance (Primary) ---
    try:
        stock = yf.Ticker(symbol)
        df = stock.history(period="2y")
        
        if not df.empty and len(df) >= 2:
            tech_data = calculate_technical_indicators(df)
            
            # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (ETF ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢) ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
            if not tech_data:
                prev_close = df['Close'].iloc[-2]
                current_price = float(df['Close'].iloc[-1])
                change_pct = ((current_price - prev_close) / prev_close) * 100
                
                print(f"‚ö†Ô∏è Using basic data only for {symbol}")
                return {
                    "price": current_price,
                    "change_pct": round(change_pct, 2),
                    "source": "yfinance_basic",
                    "rsi": None,
                    "macd": None,
                    "macd_signal": None,
                    "ema_20": None,
                    "ema_50": None,
                    "ema_200": None,
                    "bb_upper": None,
                    "bb_lower": None
                }
            
            prev_close = df['Close'].iloc[-2]
            current_price = tech_data['price']
            change_pct = ((current_price - prev_close) / prev_close) * 100
            
            tech_data['change_pct'] = round(change_pct, 2)
            tech_data['source'] = 'yfinance'
            return tech_data
        else:
            print(f"‚ö†Ô∏è Insufficient data from yfinance for {symbol}")
            
    except Exception as e:
        print(f"‚ö†Ô∏è yfinance failed for {symbol}: {e}")

    # --- Source 2: Twelve Data (Fallback) ---
    if TWELVE_DATA_KEY:
        try:
            print(f"üîÑ Falling back to Twelve Data for {symbol}...")
            url = f"https://api.twelvedata.com/quote?symbol={symbol}&apikey={TWELVE_DATA_KEY}"
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()
            
            data = resp.json()
            
            if "close" in data and "percent_change" in data:
                return {
                    "price": float(data['close']),
                    "change_pct": float(data['percent_change']),
                    "source": "twelvedata",
                    "rsi": None,
                    "macd": None,
                    "macd_signal": None,
                    "ema_20": None,
                    "ema_50": None,
                    "ema_200": None,
                    "bb_upper": None,
                    "bb_lower": None
                }
            else:
                print(f"‚ö†Ô∏è Invalid response from Twelve Data: {data}")
                
        except Exception as e:
            print(f"‚ùå Twelve Data fallback failed for {symbol}: {e}")

    print(f"‚ùå All sources failed for {symbol}")
    return None

async def main():
    global supabase
    
    # ‡∏î‡∏∂‡∏á‡∏ó‡∏±‡πâ‡∏á symbol ‡πÅ‡∏•‡∏∞ category
    res = supabase.table("stock_master").select("symbol, category").eq("is_active", True).execute()
    stocks = res.data
    
    if not stocks:
        print("üì≠ No active symbols found in stock_master.")
        return

    print(f"\nüöÄ Starting technical analysis for {len(stocks)} symbols\n")
    
    for idx, stock_data in enumerate(stocks, 1):
        symbol = stock_data['symbol']
        category = stock_data.get('category', 'Core')
        
        print(f"\n{'='*60}")
        print(f"[{idx}/{len(stocks)}] Processing: {symbol} ({category})")
        print(f"{'='*60}")
        
        data = await fetch_data_waterfall(symbol)
        
        if not data:
            print(f"‚ùå Failed: {symbol}")
            await asyncio.sleep(5)
            continue
        
        if not data.get("ema_200"):
            print(f"‚ö†Ô∏è {symbol}: No EMA 200 data")
        
        print(f"üìä Calculating metrics for {symbol}...")
        
        upside_pct = calculate_upside_pct(
            data.get("price"), 
            data.get("ema_200"),
            data.get("ema_50")
        )
        
        # ‡∏Ç‡πâ‡∏≤‡∏° analyst/sentiment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ETF
        analyst_pct = None if category == 'ETF' else fetch_analyst_data(symbol)
        sentiment = None if category == 'ETF' else fetch_sentiment_score(symbol)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á snapshot payload
        snapshot_payload = {
            "symbol": symbol,
            "price": data.get("price"),
            "change_pct": data.get("change_pct"),
            "rsi": data.get("rsi"),
            "macd": data.get("macd"),
            "macd_signal": data.get("macd_signal"),
            "ema_20": data.get("ema_20"),
            "ema_50": data.get("ema_50"),
            "ema_200": data.get("ema_200"),
            "bb_upper": data.get("bb_upper"),
            "bb_lower": data.get("bb_lower"),
            "upside_pct": upside_pct,
            "analyst_buy_pct": analyst_pct,
            "sentiment_score": sentiment,
            "recorded_at": datetime.now().isoformat()
        }
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å snapshot
        max_db_retries = 3
        for db_attempt in range(max_db_retries):
            try:
                supabase.table("stock_snapshots").insert(snapshot_payload).execute()
                print(f"‚úÖ Snapshot saved: {symbol}")
                print(f"   Price: ${data.get('price'):.2f} | Change: {data.get('change_pct'):.2f}%")
                if data.get('rsi'):
                    print(f"   RSI: {data.get('rsi'):.2f} | Upside: {upside_pct}%")
                break
            except Exception as db_error:
                print(f"‚ö†Ô∏è Database error (attempt {db_attempt + 1}/{max_db_retries}): {db_error}")
                if db_attempt < max_db_retries - 1:
                    await asyncio.sleep(2)
                    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
                else:
                    print(f"‚ùå Failed to save snapshot for {symbol}")
                    break
        
        # === ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏î‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πà‡∏≤‡∏ß ===

        if category != 'ETF':
            print(f"üì∞ Fetching news for {symbol}...")
            news_records = fetch_news_data(symbol)
            
            print(f"üìä Retrieved {len(news_records)} valid news articles")  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ
            
            if news_records:
                try:
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≤‡∏° duplicate
                    saved_count = 0
                    for news in news_records:
                        try:
                            supabase.table("stock_news").insert(news).execute()
                            saved_count += 1
                        except Exception as dup_error:
                            # ‡∏Ç‡πâ‡∏≤‡∏° error ‡∏ñ‡πâ‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏ã‡πâ‡∏≥ (unique constraint)
                            if "duplicate" not in str(dup_error).lower():
                                print(f"‚ö†Ô∏è News error: {dup_error}")
                    
                    print(f"‚úÖ Saved {saved_count}/{len(news_records)} news for {symbol}")
                    
                except Exception as news_error:
                    print(f"‚ö†Ô∏è Failed to save news for {symbol}: {news_error}")
            else:
                print(f"üì≠ No valid news found for {symbol}")
             
        # === ‡∏à‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏° ===


                # === ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏´‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏™‡∏£‡πá‡∏à ===
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì AI Prediction
        print(f"ü§ñ Calculating AI prediction for {symbol}...")
        
        # ‡∏î‡∏∂‡∏á fundamental data (‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô ETF)
        fundamental_data = None if category == 'ETF' else fetch_fundamental_data(symbol)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì overall score
        overall_score = calculate_overall_score(
            symbol=symbol,
            tech_data={
                'price': data.get('price'),
                'rsi': data.get('rsi'),
                'macd': data.get('macd'),
                'macd_signal': data.get('macd_signal'),
                'ema_20': data.get('ema_20'),
                'ema_50': data.get('ema_50'),
                'ema_200': data.get('ema_200'),
                'upside_pct': upside_pct,
                'analyst_buy_pct': analyst_pct
            },
            fundamental_data=fundamental_data,
            news_sentiment=sentiment
        )
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
        recommendation, reason, price_target = generate_recommendation(
            overall_score=overall_score,
            price=data.get('price'),
            upside_pct=upside_pct
        )
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô ai_predictions
        prediction_payload = {
            "symbol": symbol,
            "ai_model": "rule_based_v1",  # ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ rule-based
            "overall_score": overall_score,
            "recommendation": recommendation,
            "price_at_prediction": data.get('price'),
            "actual_outcome": None  # ‡∏à‡∏∞‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏´‡∏•‡∏±‡∏á 30 ‡∏ß‡∏±‡∏ô
        }
        
        try:
            supabase.table("ai_predictions").insert(prediction_payload).execute()
            print(f"‚úÖ AI Prediction saved: {symbol}")
            print(f"   Score: {overall_score}/100 | {recommendation}")
            print(f"   Reason: {reason}")
            if price_target:
                print(f"   Target: ${price_target:.2f}")
        except Exception as pred_error:
            print(f"‚ö†Ô∏è Failed to save prediction for {symbol}: {pred_error}")
        
        # === ‡∏à‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏° ===
        
        await asyncio.sleep(3)
    
    print(f"\n{'='*60}")
    print("‚úÖ Technical data collection completed!")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    asyncio.run(main())
